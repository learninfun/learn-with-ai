A Reward Function is a mathematical function that assigns rewards or penalties to different actions or decisions taken by an agent in a given environment. It is used in reinforcement learning, a sub-field of machine learning, to allow an agent to learn how to maximize its performance in a particular task or goal.

An example of a reward function can be seen in a game of chess. In this case, the reward function would assign higher rewards for actions that lead to winning the game, such as capturing the opponent's king, and lower rewards for actions that do not directly contribute to the goal, such as moving a pawn back and forth. The function may also assign negative rewards for illegal moves or mistakes that weaken the player's position. By using this reward function, the agent can learn which moves are more likely to lead to a win and adjust its behavior accordingly.