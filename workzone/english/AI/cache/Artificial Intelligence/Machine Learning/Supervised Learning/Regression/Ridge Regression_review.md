1. What is Ridge Regression?
Answer: Ridge Regression is a type of regularized linear regression that aims to prevent overfitting by adding a penalty term to the sum of squared residuals.

2. How does Ridge Regression differ from Ordinary Least Squares regression?
Answer: Ridge Regression adds a penalty term to the sum of squared residuals, whereas Ordinary Least Squares regression does not. This penalty term helps to prevent overfitting and can improve the stability of the model.

3. What is the purpose of the penalty term in Ridge Regression?
Answer: The penalty term in Ridge Regression helps to control the magnitude of the coefficients in the model. It penalizes large coefficients and encourages small ones, which can improve the stability and generalization performance of the model.

4. How is the amount of regularization in Ridge Regression controlled?
Answer: The amount of regularization in Ridge Regression is controlled by the hyperparameter lambda (Î»), which determines the strength of the penalty term. Higher values of lambda result in more regularization and smaller coefficients.

5. What are some advantages of using Ridge Regression?
Answer: Ridge Regression can help to prevent overfitting, improve the stability of the model, and handle multicollinearity between predictors. It can also be used as a feature selection tool by identifying and shrinking the coefficients of less important predictors towards zero.