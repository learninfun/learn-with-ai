1. Ensemble methods combine multiple models to improve prediction accuracy and stability.
2. Two main types of ensemble methods are averaging and boosting.
3. Averaging ensemble methods combine the predictions of multiple models using simple averaging or weighted averaging.
4. Boosting ensemble methods combine weak models sequentially to create a stronger model.
5. Bagging is a specific type of averaging ensemble method that uses bootstrap samples to train each model and reduce variance.
6. Random forests are an extension of bagging where each model is a decision tree.
7. Gradient boosting is a common type of boosting ensemble method that uses decision trees and optimization of residuals to create a stronger model.
8. Ensemble methods can be applied to various machine learning tasks, such as classification, regression, and clustering.