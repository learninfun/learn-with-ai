1. Decision trees are a data mining and machine learning tool that uses a tree-like model of decisions and their possible consequences.

2. Decision trees are used for classification and regression analysis.

3. The tree consists of internal nodes representing a feature or attribute, branches representing a decision rule or condition, and leaves representing a consequence or outcome.

4. The decision tree is constructed by recursively splitting the data into smaller and smaller subgroups based on the best attribute to split on.

5. Decision trees have a simple and intuitive graphical representation that humans can understand and interpret easily.

6. They can be used for both supervised and unsupervised learning.

7. Decision trees suffer from overfitting, which can be addressed by pruning the tree or using ensemble techniques.

8. Decision tree algorithms include ID3, C4.5, CART, and CHAID.

9. Decision trees have many real-world applications, such as in finance, medicine, and marketing.