1) What is the primary goal of using a decision tree in data analysis?
Answer: The primary goal is to create a model that predicts outcomes by analyzing input variables and decision paths.

2) What is the difference between a classification tree and a regression tree?
Answer: A classification tree predicts outcomes as discrete categories (e.g. yes/no, red/green/blue), while a regression tree predicts outcomes as continuous numeric values (e.g. height, weight).

3) How does pruning a decision tree impact its accuracy?
Answer: Pruning removes branches and decision nodes that do not significantly contribute to the model, which can improve accuracy by reducing overfitting.

4) Can decision trees handle missing data? If so, how?
Answer: Yes, decision trees can handle missing data through various methods, such as imputing missing values using mean or median substitution, or using algorithms that deal with missing data directly.

5) What is the Gini impurity index and how is it used in decision trees?
Answer: The Gini impurity index is a measure of how often a randomly chosen element from a set would be incorrectly labeled if it were randomly labeled according to the distribution of labels in the subset. It is used in decision trees to determine how well a feature splits the data into different categories. A lower Gini impurity index indicates a better split.