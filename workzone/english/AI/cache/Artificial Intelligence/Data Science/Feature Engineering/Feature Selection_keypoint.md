1. Feature selection is the process of identifying and selecting relevant features from a set of variables or predictors.

2. There are different types of feature selection techniques such as filter, wrapper, and embedded methods.

3. Filter methods use statistical measures to rank and select relevant features.

4. Wrapper methods use machine learning algorithms to evaluate the performance of subsets of features.

5. Embedded methods combine feature selection with model building, selecting features during the model development process.

6. Feature selection can improve model performance by reducing overfitting, decreasing training time, and increasing interpretability.

7. Feature selection should be done after data pre-processing and data cleaning to ensure data quality.

8. The choice of feature selection technique depends on the problem context and the available data.

9. The impact of feature selection on the performance of the model should be measured and compared with the performance without feature selection.