1. What is Feature Selection?
Answer: Feature Selection is a process of selecting a subset of relevant features (variables) from a larger set of features to improve the performance of a machine learning model.

2. Why is Feature Selection important in machine learning?
Answer: Feature Selection reduces the dimensionality of the dataset, which leads to improved model performance, reduces overfitting, decreases the training time and simplifies the model.

3. What are the methods used for Feature Selection?
Answer: There are many methods for Feature Selection, such as Filter Methods, Wrapper Methods, Embedded Methods, and Hybrid Methods.

4. Explain Wrapper Methods in Feature Selection?
Answer: Wrapper Methods are iterative methods that evaluate a subset of features for each iteration and identify the set of features that gives the best performance.

5. What criteria do we use for Feature Selection?
Answer: We use different criteria for Feature Selection, such as Information Gain, Correlation, Mutual Information, Fisher score, Chi-Square, Recursive Feature Elimination, etc.