1. Model accuracy or predictive power should be assessed to evaluate a model's performance. 

2. Different metrics can be used to evaluate model performance depending on the problem statement and the type of model used. For example, mean squared error is used to evaluate linear regression models while confusion matrix is used in classification models. 

3. Train-test split or cross-validation is used to assess the model's performance on unseen data. 

4. Overfitting of the model can be evaluated by comparing the training and test set performance. 

5. Model interpretation can also be evaluated through feature importance analysis to understand the impact of each input variable on model output. 

6. Model complexity vs. interpretability tradeoff should be analyzed while selecting a suitable model. 

7. Bias-variance tradeoff plays a crucial role in the evaluation of the model. 

8. Ensembling can be implemented for improving model performance. 

9. Model evaluation is an iterative process, and models should be updated continuously to ensure optimal performance. 

10. Business context and requirements should also be considered while evaluating the model to avoid any unwarranted consequences.