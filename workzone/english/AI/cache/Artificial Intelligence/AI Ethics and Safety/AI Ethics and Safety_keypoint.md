1. Transparency and Explainability: AI systems should be designed in a way that their decision-making processes are transparent and can be explained to users.

2. Accountability: AI systems should be accountable for their actions and behaviors. This includes holding the creators, developers, and users of AI systems responsible for any harm caused.

3. Fairness and Justice: AI systems should be designed to avoid discrimination or bias against any individual or group based on race, gender, religion, or any other factor.

4. Privacy: AI systems should respect the privacy of individuals and personal data. This includes protecting confidential data and respecting the right of individuals to control their own personal information.

5. Safety and Reliability: AI systems should be designed in a way that they are safe, reliable, dependable, and consistent in their performance.

6. Human Control and Autonomy: AI systems should be designed in a way that they are subject to human control, and humans should always have the authority to overrule automated decisions.

7. Societal and Environmental Impact: AI systems should be designed in a way that they have a positive impact on people's lives and the environment.

8. Ethical Research and Deployment: AI systems should be developed and deployed with ethical considerations in mind. This includes transparency, accountability, social responsibility, and human welfare in all phases of research, development, and deployment.