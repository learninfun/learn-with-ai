1. 什麼是Bagging集成方法？請描述其基本思想與運作流程。
2. 什麼是AdaBoost集成方法？請描述其基本思想與運作流程。
3. 什麼是Gradient Boosting集成方法？請描述其基本思想與運作流程。
4. 什麼是Stacking集成方法？請描述其基本思想與運作流程。
5. 集成方法中，如何決定基模型的個數？有什麼常用的方法？

答案：
1. Bagging集成方法是通過對原始數據進行有放回的抽樣，生成多個子集，然後在每個子集上訓練一個基模型，最後將這些基模型的結果進行平均或投票等操作，得到最終預測結果。
2. AdaBoost集成方法是通過加權決策，在每一輪訓練中將樣本權重調整，增加被分類錯誤的樣本權重，減少被分類正確的樣本權重。在基模型中，也會加上權重，最後結合基模型的結果，得到最終預測結果。
3. Gradient Boosting集成方法是通過利用梯度下降方法，根據損失函數的梯度信息，將前一輪的誤差預測結果，作為訓練下一輪基模型的輸入。每輪訓練得到的基模型的結果，再進行加權總和，得到最終結果。
4. Stacking集成方法是將多個不同的基模型結果作為輸入，通過訓練一個次級模型，學習如何結合這些輸入，得到最終預測結果。
5. 決定基模型的個數，可以通過交叉驗證、網格搜索等方法進行調參。常用的方法包括Bagging方法、Boosting方法等。在實際應用中，也需要考慮運算效率等方面的因素，選擇適宜的基模型數量。