AI倫理和安全是指 ：在開發、運用人工智慧技術時，要遵從人類社會的倫理道德規範，並確保AI系統不會對人類和環境造成損害。

舉例來說，當研發新型人工智慧設備時，必須遵守尊重隱私、反歧視、不傷害等基本倫理要求。在運用人工智慧的同時，必須確保AI算法的公正性和透明度，不會對某些特定群體產生歧視和排斥。此外，對於某些可預測的情況，AI還需要主動設定保障機制，防止因AI系統運作失誤而導致的安全風險，如在無人駕駛汽車中定制緊急停車或轉向措施，以保護乘客和其他路人乘客的安全。