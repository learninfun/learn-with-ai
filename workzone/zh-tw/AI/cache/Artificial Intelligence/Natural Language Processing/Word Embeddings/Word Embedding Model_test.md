1. 什麼是Word Embedding Model？
答案：Word Embedding Model是一種自然語言處理技術，將單詞轉換為低維向量表示形式，以利於模型更好地理解自然語言。

2. Word2Vec模型是如何訓練的？
答案：Word2Vec模型通常使用神經網絡訓練，其中一種訓練方法是「連續詞袋」方法，該方法通過預測一個單詞的上下文來訓練模型。

3. GloVe模型中的「共現矩陣」指的是什麼？
答案：GloVe模型中，「共現矩陣」是一個矩陣，用於記錄每個單詞出現在另一個單詞的上下文中的頻率。

4. 在FastText模型中，為什麼使用n-gram？
答案： FastText模型使用n-gram，可以有效處理未知單詞和常見的拼寫錯誤，同時提高詞向量的魯棒性。

5. Word Embedding Model中的「one-hot encoding」用於什麼？
答案： Word Embedding Model中，「one-hot encoding」是一種將單詞轉換為向量表示的方法，其中每個單詞都表示為一個唯一的向量，該向量在一個維度上為1，其他維度上為0。