1. Support Vector Machines (SVM) 在什麼情況下表現最佳？
2. 請解釋SVM中的Kernel Trick是怎麼運作的？
3. 如何處理在SVM中的類別不平衡問題？
4. 當SVM中的兩類資料點完全分開，且具有較大的邊緣(margin)時，該如何進行超平面的選擇？
5. SVM的目標函數是什麼，並請說明其所代表的意義？

答案：
1. SVM在到達最佳分類效能時，且擁有良好的數據分類能力。
2. Kernel Trick 以非線性轉換將資料映射至高維度空間，藉此實現在低維度空間中難以分割的資料，因而提高分類的效能。
3. 常見的處理方式有：使用代價數據，將代價賦予錯誤預測的情況；使用在不同特徵上的重量，以排除資料不平衡的影響。
4. 超平面的選擇會影響SVM的分類效能，因此可透過"soft margin"的方法，允許資料點在小部分情況下不被分開。
5. SVM的目標函數為最小化平方加權的姐妹距離，其所代表的意義為：以最大差距為標準，將支援向量分佈在相反方向，以產生最大化的margin(邊界)。