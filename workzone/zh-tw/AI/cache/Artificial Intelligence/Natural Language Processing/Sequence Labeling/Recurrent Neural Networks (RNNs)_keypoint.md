1. RNN是一種神經網路架構，主要用於處理序列數據。
2. RNN的基本建構是將先前的輸出作為當前輸入的一部分，這樣可以在處理序列數據時保留時間信息。
3. RNN的一個重要變形是Long Short-Term Memory (LSTM)，其增加了記憶單元和遺忘機制，能夠更好地處理長序列數據。
4. RNN可應用於多個領域，如語言模型、機器翻譯、語音識別、圖像描述等。
5. RNN的訓練通常使用反向傳播算法，並且需要考慮如何處理序列尺寸不同的數據，如padding和截斷。
6. RNN的模型複雜度相對較高，容易出現過擬合現象，因此需要進行正規化和dropout等機制。
7. 目前在RNN上的研究主要包括如何改進訓練算法、如何應用於更多領域、如何設計更有效的模型結構等。