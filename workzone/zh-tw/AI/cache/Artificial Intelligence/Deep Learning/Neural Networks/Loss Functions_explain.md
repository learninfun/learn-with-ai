Loss Functions是在深度學習中用來衡量模型預測與實際值之間差距的函數。這個函數會計算預測值和實際值之間的誤差，並將其轉換成數值，以便在訓練期間使用梯度下降算法最小化它。

下面是幾種常見的Loss Functions及其例子：

1. 均方誤差(Mean Squared Error, MSE)：計算預測值和實際值之間的平均平方誤差。例如，當要預測房屋價格時，MSE可以衡量預測值與實際價格之間的誤差。

2. 交叉熵(Cross-Entropy)：用於衡量分類問題中預測類別與實際類別之間的不匹配程度。例如，當要對圖像中的物體進行分類時，交叉熵可以衡量預測的類別與實際類別之間的差距。

3. KL散度(Kullback-Leibler Divergence, KL Divergence)：用於衡量機器學習模型中兩個機率分布之間的距離。例如，在生成對抗網絡(GAN)中，KL散度用於衡量生成器生成的圖像分布和真實圖像分布之間的相似程度。

4. 聚類損失(Cluster Loss)：用於衡量聚類模型中預測聚類與真實聚類之間的距離。例如，在文本聚類模型中，聚類損失可以衡量預測的文章分組與實際的分組之間的誤差。