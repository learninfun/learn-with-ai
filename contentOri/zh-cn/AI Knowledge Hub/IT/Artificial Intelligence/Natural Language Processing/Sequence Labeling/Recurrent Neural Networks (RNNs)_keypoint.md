1. RNN是一种神经网路架构，主要用于处理序列数据。
2. RNN的基本建构是将先前的输出作为当前输入的一部分，这样可以在处理序列数据时保留时间信息。
3. RNN的一个重要变形是Long Short-Term Memory (LSTM)，其增加了记忆单元和遗忘机制，能够更好地处理长序列数据。
4. RNN可应用于多个领域，如语言模型、机器翻译、语音识别、图像描述等。
5. RNN的训练通常使用反向传播算法，并且需要考虑如何处理序列尺寸不同的数据，如padding和截断。
6. RNN的模型复杂度相对较高，容易出现过拟合现象，因此需要进行正规化和dropout等机制。
7. 目前在RNN上的研究主要包括如何改进训练算法、如何应用于更多领域、如何设计更有效的模型结构等。