1. 什么是Word Embedding Model？
答案：Word Embedding Model是一种自然语言处理技术，将单词转换为低维向量表示形式，以利于模型更好地理解自然语言。

2. Word2Vec模型是如何训练的？
答案：Word2Vec模型通常使用神经网络训练，其中一种训练方法是“连续词袋”方法，该方法通过预测一个单词的上下文来训练模型。

3. GloVe模型中的“共现矩阵”指的是什么？
答案：GloVe模型中，“共现矩阵”是一个矩阵，用于记录每个单词出现在另一个单词的上下文中的频率。

4. 在FastText模型中，为什么使用n-gram？
答案： FastText模型使用n-gram，可以有效处理未知单词和常见的拼写错误，同时提高词向量的鲁棒性。

5. Word Embedding Model中的“one-hot encoding”用于什么？
答案： Word Embedding Model中，“one-hot encoding”是一种将单词转换为向量表示的方法，其中每个单词都表示为一个唯一的向量，该向量在一个维度上为1，其他维度上为0。