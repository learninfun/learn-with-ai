AI伦理和安全是指 ：在开发、运用人工智慧技术时，要遵从人类社会的伦理道德规范，并确保AI系统不会对人类和环境造成损害。

举例来说，当研发新型人工智慧设备时，必须遵守尊重隐私、反歧视、不伤害等基本伦理要求。在运用人工智慧的同时，必须确保AI算法的公正性和透明度，不会对某些特定群体产生歧视和排斥。此外，对于某些可预测的情况，AI还需要主动设定保障机制，防止因AI系统运作失误而导致的安全风险，如在无人驾驶汽车中定制紧急停车或转向措施，以保护乘客和其他路人乘客的安全。