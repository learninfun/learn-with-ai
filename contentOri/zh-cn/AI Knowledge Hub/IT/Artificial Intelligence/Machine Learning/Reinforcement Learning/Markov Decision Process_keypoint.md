1. 状态(State)：系统可能处于的不同状态
2. 行动(Action)：系统可执行的各种行动
3. 状态转移函数(Transition Function)：描述系统如何由一个状态转移到另一个状态，并受行动影响
4. 即时奖励函数(Reward Function)：描述当系统处于某个状态且采取某个行动时，获得的即时奖励值
5. 持续时间收益(Return)：在一个序列操作中，按照当前策略采取一系列行动后，获得的总收益
6. 策略(Policy)：系统在各个状态下，选择执行哪个行动的策略
7. 优化问题(Optimization Problem)：在已知系统的状态转移函数、即时奖励函数和策略的情况下，如何设计最优策略使得持续时间收益最大化
8. 广义策略迭代(Generalized Policy Iteration)：以价值函数(Value Function)和策略迭代(PI)交替进行的一种模型学习算法
9. Q-Learning算法：一种不需要事先知道状态转移函数的基于Q值学习法则的强化学习算法
10. 蒙特卡洛方法(Monte Carlo Method)：直接从经验中学习策略的一种方法，通过对环境进行多次仿真实验，获得期望收益和状态转移函数等信息，进而学习最优策略